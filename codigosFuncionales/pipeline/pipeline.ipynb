{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: e_coli_driams_b_2000_20000Da_v2 (1).csv Bacteria: Cefepime\n",
      "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 5984, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 5984, 64)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 2984, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 2984, 128)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 1488, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 1488, 256)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 740, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 740, 256)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 94720)             0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 94720)             0         \n",
      "                                                                 \n",
      " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
      "                                                                 \n",
      " fully_connected_1 (Dense)   (None, 64)                16448     \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 64)                4160      \n",
      "                                                                 \n",
      " OUT_Layer (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,839,105\n",
      "Trainable params: 24,837,697\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 3s 80ms/step - loss: 6.9601 - tp: 3.0000 - fp: 17.0000 - tn: 106.0000 - fn: 27.0000 - accuracy: 0.7124 - precision: 0.1500 - recall: 0.1000 - auc: 0.4950 - prc: 0.1887 - val_loss: 6.7881 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1538 - val_prc: 0.1444 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.7326 - tp: 5.0000 - fp: 7.0000 - tn: 116.0000 - fn: 25.0000 - accuracy: 0.7908 - precision: 0.4167 - recall: 0.1667 - auc: 0.5687 - prc: 0.2768 - val_loss: 6.7057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2692 - val_prc: 0.1571 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.5996 - tp: 7.0000 - fp: 22.0000 - tn: 101.0000 - fn: 23.0000 - accuracy: 0.7059 - precision: 0.2414 - recall: 0.2333 - auc: 0.5924 - prc: 0.2792 - val_loss: 6.5877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5437 - tp: 2.0000 - fp: 8.0000 - tn: 115.0000 - fn: 28.0000 - accuracy: 0.7647 - precision: 0.2000 - recall: 0.0667 - auc: 0.5356 - prc: 0.2161 - val_loss: 6.5420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4231 - val_prc: 0.1888 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4210 - tp: 3.0000 - fp: 9.0000 - tn: 114.0000 - fn: 27.0000 - accuracy: 0.7647 - precision: 0.2500 - recall: 0.1000 - auc: 0.6324 - prc: 0.2499 - val_loss: 6.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4615 - val_prc: 0.2057 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3472 - tp: 3.0000 - fp: 12.0000 - tn: 111.0000 - fn: 27.0000 - accuracy: 0.7451 - precision: 0.2000 - recall: 0.1000 - auc: 0.6917 - prc: 0.2916 - val_loss: 6.4049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6058 - val_prc: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.2808 - tp: 4.0000 - fp: 8.0000 - tn: 115.0000 - fn: 26.0000 - accuracy: 0.7778 - precision: 0.3333 - recall: 0.1333 - auc: 0.6863 - prc: 0.3413 - val_loss: 6.3581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3846 - val_prc: 0.1800 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.1927 - tp: 6.0000 - fp: 4.0000 - tn: 119.0000 - fn: 24.0000 - accuracy: 0.8170 - precision: 0.6000 - recall: 0.2000 - auc: 0.7241 - prc: 0.4085 - val_loss: 6.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2692 - val_prc: 0.1560 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.1609 - tp: 5.0000 - fp: 9.0000 - tn: 114.0000 - fn: 25.0000 - accuracy: 0.7778 - precision: 0.3571 - recall: 0.1667 - auc: 0.7192 - prc: 0.3209 - val_loss: 6.2876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1923 - val_prc: 0.1467 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.0866 - tp: 7.0000 - fp: 5.0000 - tn: 118.0000 - fn: 23.0000 - accuracy: 0.8170 - precision: 0.5833 - recall: 0.2333 - auc: 0.7396 - prc: 0.4766 - val_loss: 6.2187 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2308 - val_prc: 0.1516 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0511 - tp: 5.0000 - fp: 5.0000 - tn: 118.0000 - fn: 25.0000 - accuracy: 0.8039 - precision: 0.5000 - recall: 0.1667 - auc: 0.7329 - prc: 0.3880 - val_loss: 6.2089 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2692 - val_prc: 0.1587 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.9624 - tp: 10.0000 - fp: 7.0000 - tn: 116.0000 - fn: 20.0000 - accuracy: 0.8235 - precision: 0.5882 - recall: 0.3333 - auc: 0.8133 - prc: 0.4633 - val_loss: 6.1377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3269 - val_prc: 0.1657 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8787 - tp: 8.0000 - fp: 4.0000 - tn: 119.0000 - fn: 22.0000 - accuracy: 0.8301 - precision: 0.6667 - recall: 0.2667 - auc: 0.8619 - prc: 0.5924 - val_loss: 6.0890 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3558 - val_prc: 0.1719 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8647 - tp: 18.0000 - fp: 13.0000 - tn: 110.0000 - fn: 12.0000 - accuracy: 0.8366 - precision: 0.5806 - recall: 0.6000 - auc: 0.8443 - prc: 0.5992 - val_loss: 6.0252 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3365 - val_prc: 0.1759 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 5.8412 - tp: 13.0000 - fp: 10.0000 - tn: 113.0000 - fn: 17.0000 - accuracy: 0.8235 - precision: 0.5652 - recall: 0.4333 - auc: 0.8314 - prc: 0.5375 - val_loss: 6.1391 - val_tp: 4.0000 - val_fp: 10.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4118 - val_precision: 0.2857 - val_recall: 1.0000 - val_auc: 0.5769 - val_prc: 0.2686 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.7600 - tp: 14.0000 - fp: 4.0000 - tn: 119.0000 - fn: 16.0000 - accuracy: 0.8693 - precision: 0.7778 - recall: 0.4667 - auc: 0.8369 - prc: 0.6960 - val_loss: 6.0913 - val_tp: 4.0000 - val_fp: 9.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4706 - val_precision: 0.3077 - val_recall: 1.0000 - val_auc: 0.6346 - val_prc: 0.2804 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.6590 - tp: 17.0000 - fp: 5.0000 - tn: 118.0000 - fn: 13.0000 - accuracy: 0.8824 - precision: 0.7727 - recall: 0.5667 - auc: 0.9130 - prc: 0.7687 - val_loss: 5.9588 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7212 - val_prc: 0.3508 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 5.6584 - tp: 13.0000 - fp: 4.0000 - tn: 119.0000 - fn: 17.0000 - accuracy: 0.8627 - precision: 0.7647 - recall: 0.4333 - auc: 0.8817 - prc: 0.7006 - val_loss: 5.9927 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 12.0000 - val_fn: 4.0000 - val_accuracy: 0.7059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7404 - val_prc: 0.3524 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.6521 - tp: 15.0000 - fp: 5.0000 - tn: 118.0000 - fn: 15.0000 - accuracy: 0.8693 - precision: 0.7500 - recall: 0.5000 - auc: 0.8573 - prc: 0.6609 - val_loss: 5.8970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7596 - val_prc: 0.3536 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.6413 - tp: 15.0000 - fp: 10.0000 - tn: 113.0000 - fn: 15.0000 - accuracy: 0.8366 - precision: 0.6000 - recall: 0.5000 - auc: 0.8556 - prc: 0.6038 - val_loss: 5.8431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6635 - val_prc: 0.4695 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.6006 - tp: 10.0000 - fp: 2.0000 - tn: 121.0000 - fn: 20.0000 - accuracy: 0.8562 - precision: 0.8333 - recall: 0.3333 - auc: 0.8882 - prc: 0.6660 - val_loss: 6.0244 - val_tp: 4.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2353 - val_precision: 0.2353 - val_recall: 1.0000 - val_auc: 0.6731 - val_prc: 0.2884 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.5166 - tp: 13.0000 - fp: 7.0000 - tn: 116.0000 - fn: 17.0000 - accuracy: 0.8431 - precision: 0.6500 - recall: 0.4333 - auc: 0.9046 - prc: 0.6853 - val_loss: 6.0247 - val_tp: 4.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2353 - val_precision: 0.2353 - val_recall: 1.0000 - val_auc: 0.4808 - val_prc: 0.2079 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 5.4793 - tp: 14.0000 - fp: 7.0000 - tn: 116.0000 - fn: 16.0000 - accuracy: 0.8497 - precision: 0.6667 - recall: 0.4667 - auc: 0.9122 - prc: 0.6978 - val_loss: 6.0937 - val_tp: 4.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2353 - val_precision: 0.2353 - val_recall: 1.0000 - val_auc: 0.7308 - val_prc: 0.3288 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.4641 - tp: 21.0000 - fp: 6.0000 - tn: 117.0000 - fn: 9.0000 - accuracy: 0.9020 - precision: 0.7778 - recall: 0.7000 - auc: 0.9035 - prc: 0.7199 - val_loss: 6.0639 - val_tp: 4.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2353 - val_precision: 0.2353 - val_recall: 1.0000 - val_auc: 0.7596 - val_prc: 0.3536 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 5984, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 5984, 64)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 2984, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 2984, 128)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 1488, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 1488, 256)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 740, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 740, 256)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 94720)             0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 94720)             0         \n",
      "                                                                 \n",
      " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
      "                                                                 \n",
      " fully_connected_1 (Dense)   (None, 64)                16448     \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 64)                4160      \n",
      "                                                                 \n",
      " OUT_Layer (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,839,105\n",
      "Trainable params: 24,837,697\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 61ms/step - loss: 7.3589 - tp: 56.0000 - fp: 47.0000 - tn: 123.0000 - fn: 61.0000 - accuracy: 0.6237 - precision: 0.5437 - recall: 0.4786 - auc: 0.5947 - prc: 0.5015 - val_loss: 6.7644 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.8103 - tp: 51.0000 - fp: 33.0000 - tn: 103.0000 - fn: 57.0000 - accuracy: 0.6311 - precision: 0.6071 - recall: 0.4722 - auc: 0.6791 - prc: 0.5829 - val_loss: 6.7173 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.5826 - tp: 67.0000 - fp: 28.0000 - tn: 108.0000 - fn: 41.0000 - accuracy: 0.7172 - precision: 0.7053 - recall: 0.6204 - auc: 0.7833 - prc: 0.7199 - val_loss: 6.6605 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 2.0000 - val_accuracy: 0.9286 - val_precision: 1.0000 - val_recall: 0.9286 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.5417 - tp: 70.0000 - fp: 37.0000 - tn: 99.0000 - fn: 38.0000 - accuracy: 0.6926 - precision: 0.6542 - recall: 0.6481 - auc: 0.7615 - prc: 0.7180 - val_loss: 6.5012 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 6.4312 - tp: 80.0000 - fp: 37.0000 - tn: 99.0000 - fn: 28.0000 - accuracy: 0.7336 - precision: 0.6838 - recall: 0.7407 - auc: 0.8106 - prc: 0.7676 - val_loss: 6.6476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 28.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 6.4068 - tp: 70.0000 - fp: 25.0000 - tn: 111.0000 - fn: 38.0000 - accuracy: 0.7418 - precision: 0.7368 - recall: 0.6481 - auc: 0.7960 - prc: 0.7246 - val_loss: 6.6388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 28.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.2595 - tp: 82.0000 - fp: 31.0000 - tn: 105.0000 - fn: 26.0000 - accuracy: 0.7664 - precision: 0.7257 - recall: 0.7593 - auc: 0.8432 - prc: 0.8015 - val_loss: 6.4476 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 25.0000 - val_accuracy: 0.1071 - val_precision: 1.0000 - val_recall: 0.1071 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.2160 - tp: 74.0000 - fp: 25.0000 - tn: 111.0000 - fn: 34.0000 - accuracy: 0.7582 - precision: 0.7475 - recall: 0.6852 - auc: 0.8394 - prc: 0.8361 - val_loss: 6.2891 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.0919 - tp: 84.0000 - fp: 23.0000 - tn: 113.0000 - fn: 24.0000 - accuracy: 0.8074 - precision: 0.7850 - recall: 0.7778 - auc: 0.8882 - prc: 0.8461 - val_loss: 6.2399 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.0034 - tp: 91.0000 - fp: 20.0000 - tn: 116.0000 - fn: 17.0000 - accuracy: 0.8484 - precision: 0.8198 - recall: 0.8426 - auc: 0.9094 - prc: 0.8948 - val_loss: 6.1678 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 6.0764 - tp: 75.0000 - fp: 26.0000 - tn: 110.0000 - fn: 33.0000 - accuracy: 0.7582 - precision: 0.7426 - recall: 0.6944 - auc: 0.8580 - prc: 0.8432 - val_loss: 6.0929 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 5.9834 - tp: 90.0000 - fp: 23.0000 - tn: 113.0000 - fn: 18.0000 - accuracy: 0.8320 - precision: 0.7965 - recall: 0.8333 - auc: 0.8883 - prc: 0.8565 - val_loss: 6.0332 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 5.7885 - tp: 93.0000 - fp: 14.0000 - tn: 122.0000 - fn: 15.0000 - accuracy: 0.8811 - precision: 0.8692 - recall: 0.8611 - auc: 0.9480 - prc: 0.9433 - val_loss: 6.0769 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.8610 - tp: 81.0000 - fp: 20.0000 - tn: 116.0000 - fn: 27.0000 - accuracy: 0.8074 - precision: 0.8020 - recall: 0.7500 - auc: 0.8996 - prc: 0.8821 - val_loss: 6.0060 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.7260 - tp: 94.0000 - fp: 15.0000 - tn: 121.0000 - fn: 14.0000 - accuracy: 0.8811 - precision: 0.8624 - recall: 0.8704 - auc: 0.9404 - prc: 0.9339 - val_loss: 5.9849 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 2.0000 - val_accuracy: 0.9286 - val_precision: 1.0000 - val_recall: 0.9286 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 5.7369 - tp: 89.0000 - fp: 22.0000 - tn: 114.0000 - fn: 19.0000 - accuracy: 0.8320 - precision: 0.8018 - recall: 0.8241 - auc: 0.9221 - prc: 0.9078 - val_loss: 6.1372 - val_tp: 6.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 22.0000 - val_accuracy: 0.2143 - val_precision: 1.0000 - val_recall: 0.2143 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.7047 - tp: 85.0000 - fp: 17.0000 - tn: 119.0000 - fn: 23.0000 - accuracy: 0.8361 - precision: 0.8333 - recall: 0.7870 - auc: 0.9191 - prc: 0.9067 - val_loss: 5.5563 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.5257 - tp: 99.0000 - fp: 12.0000 - tn: 124.0000 - fn: 9.0000 - accuracy: 0.9139 - precision: 0.8919 - recall: 0.9167 - auc: 0.9724 - prc: 0.9690 - val_loss: 5.4937 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.5514 - tp: 89.0000 - fp: 13.0000 - tn: 123.0000 - fn: 19.0000 - accuracy: 0.8689 - precision: 0.8725 - recall: 0.8241 - auc: 0.9521 - prc: 0.9396 - val_loss: 5.4186 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.5087 - tp: 95.0000 - fp: 17.0000 - tn: 119.0000 - fn: 13.0000 - accuracy: 0.8770 - precision: 0.8482 - recall: 0.8796 - auc: 0.9525 - prc: 0.9510 - val_loss: 5.3115 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.4323 - tp: 96.0000 - fp: 12.0000 - tn: 124.0000 - fn: 12.0000 - accuracy: 0.9016 - precision: 0.8889 - recall: 0.8889 - auc: 0.9689 - prc: 0.9617 - val_loss: 5.2767 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.3932 - tp: 93.0000 - fp: 9.0000 - tn: 127.0000 - fn: 15.0000 - accuracy: 0.9016 - precision: 0.9118 - recall: 0.8611 - auc: 0.9700 - prc: 0.9636 - val_loss: 5.2637 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.3541 - tp: 96.0000 - fp: 10.0000 - tn: 126.0000 - fn: 12.0000 - accuracy: 0.9098 - precision: 0.9057 - recall: 0.8889 - auc: 0.9715 - prc: 0.9664 - val_loss: 5.2579 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.4370 - tp: 91.0000 - fp: 18.0000 - tn: 118.0000 - fn: 17.0000 - accuracy: 0.8566 - precision: 0.8349 - recall: 0.8426 - auc: 0.9360 - prc: 0.9335 - val_loss: 5.1605 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.3048 - tp: 95.0000 - fp: 9.0000 - tn: 127.0000 - fn: 13.0000 - accuracy: 0.9098 - precision: 0.9135 - recall: 0.8796 - auc: 0.9692 - prc: 0.9627 - val_loss: 5.1041 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.1962 - tp: 101.0000 - fp: 3.0000 - tn: 133.0000 - fn: 7.0000 - accuracy: 0.9590 - precision: 0.9712 - recall: 0.9352 - auc: 0.9860 - prc: 0.9858 - val_loss: 5.0565 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.2198 - tp: 101.0000 - fp: 7.0000 - tn: 129.0000 - fn: 7.0000 - accuracy: 0.9426 - precision: 0.9352 - recall: 0.9352 - auc: 0.9731 - prc: 0.9700 - val_loss: 5.0136 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.1432 - tp: 96.0000 - fp: 8.0000 - tn: 128.0000 - fn: 12.0000 - accuracy: 0.9180 - precision: 0.9231 - recall: 0.8889 - auc: 0.9858 - prc: 0.9831 - val_loss: 4.9849 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.0913 - tp: 99.0000 - fp: 6.0000 - tn: 130.0000 - fn: 9.0000 - accuracy: 0.9385 - precision: 0.9429 - recall: 0.9167 - auc: 0.9900 - prc: 0.9878 - val_loss: 4.9483 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 5.1498 - tp: 99.0000 - fp: 14.0000 - tn: 122.0000 - fn: 9.0000 - accuracy: 0.9057 - precision: 0.8761 - recall: 0.9167 - auc: 0.9720 - prc: 0.9674 - val_loss: 4.9481 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 5.0308 - tp: 101.0000 - fp: 4.0000 - tn: 132.0000 - fn: 7.0000 - accuracy: 0.9549 - precision: 0.9619 - recall: 0.9352 - auc: 0.9898 - prc: 0.9890 - val_loss: 4.9662 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.9964 - tp: 101.0000 - fp: 5.0000 - tn: 131.0000 - fn: 7.0000 - accuracy: 0.9508 - precision: 0.9528 - recall: 0.9352 - auc: 0.9911 - prc: 0.9903 - val_loss: 4.8662 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.9995 - tp: 102.0000 - fp: 9.0000 - tn: 127.0000 - fn: 6.0000 - accuracy: 0.9385 - precision: 0.9189 - recall: 0.9444 - auc: 0.9874 - prc: 0.9862 - val_loss: 4.8487 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.9766 - tp: 99.0000 - fp: 5.0000 - tn: 131.0000 - fn: 9.0000 - accuracy: 0.9426 - precision: 0.9519 - recall: 0.9167 - auc: 0.9870 - prc: 0.9840 - val_loss: 4.8685 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.8816 - tp: 105.0000 - fp: 3.0000 - tn: 133.0000 - fn: 3.0000 - accuracy: 0.9754 - precision: 0.9722 - recall: 0.9722 - auc: 0.9955 - prc: 0.9947 - val_loss: 4.7874 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 4.9017 - tp: 100.0000 - fp: 6.0000 - tn: 130.0000 - fn: 8.0000 - accuracy: 0.9426 - precision: 0.9434 - recall: 0.9259 - auc: 0.9862 - prc: 0.9874 - val_loss: 4.8152 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.8263 - tp: 104.0000 - fp: 4.0000 - tn: 132.0000 - fn: 4.0000 - accuracy: 0.9672 - precision: 0.9630 - recall: 0.9630 - auc: 0.9962 - prc: 0.9952 - val_loss: 4.7586 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.8389 - tp: 101.0000 - fp: 4.0000 - tn: 132.0000 - fn: 7.0000 - accuracy: 0.9549 - precision: 0.9619 - recall: 0.9352 - auc: 0.9920 - prc: 0.9905 - val_loss: 4.7199 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.0159 - tp: 97.0000 - fp: 17.0000 - tn: 119.0000 - fn: 11.0000 - accuracy: 0.8852 - precision: 0.8509 - recall: 0.8981 - auc: 0.9535 - prc: 0.9420 - val_loss: 4.6985 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.8158 - tp: 100.0000 - fp: 6.0000 - tn: 130.0000 - fn: 8.0000 - accuracy: 0.9426 - precision: 0.9434 - recall: 0.9259 - auc: 0.9853 - prc: 0.9830 - val_loss: 4.7824 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.7713 - tp: 101.0000 - fp: 7.0000 - tn: 129.0000 - fn: 7.0000 - accuracy: 0.9426 - precision: 0.9352 - recall: 0.9352 - auc: 0.9909 - prc: 0.9887 - val_loss: 4.7172 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.7586 - tp: 99.0000 - fp: 5.0000 - tn: 131.0000 - fn: 9.0000 - accuracy: 0.9426 - precision: 0.9519 - recall: 0.9167 - auc: 0.9865 - prc: 0.9874 - val_loss: 4.6278 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.6857 - tp: 104.0000 - fp: 3.0000 - tn: 133.0000 - fn: 4.0000 - accuracy: 0.9713 - precision: 0.9720 - recall: 0.9630 - auc: 0.9957 - prc: 0.9948 - val_loss: 4.5814 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.6233 - tp: 107.0000 - fp: 2.0000 - tn: 134.0000 - fn: 1.0000 - accuracy: 0.9877 - precision: 0.9817 - recall: 0.9907 - auc: 0.9987 - prc: 0.9983 - val_loss: 4.5587 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.6441 - tp: 103.0000 - fp: 5.0000 - tn: 131.0000 - fn: 5.0000 - accuracy: 0.9590 - precision: 0.9537 - recall: 0.9537 - auc: 0.9941 - prc: 0.9930 - val_loss: 4.5485 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.5733 - tp: 106.0000 - fp: 1.0000 - tn: 135.0000 - fn: 2.0000 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9815 - auc: 0.9993 - prc: 0.9991 - val_loss: 4.5065 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.6336 - tp: 104.0000 - fp: 6.0000 - tn: 130.0000 - fn: 4.0000 - accuracy: 0.9590 - precision: 0.9455 - recall: 0.9630 - auc: 0.9857 - prc: 0.9857 - val_loss: 4.4996 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.5800 - tp: 105.0000 - fp: 2.0000 - tn: 134.0000 - fn: 3.0000 - accuracy: 0.9795 - precision: 0.9813 - recall: 0.9722 - auc: 0.9921 - prc: 0.9922 - val_loss: 4.4809 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.5576 - tp: 104.0000 - fp: 8.0000 - tn: 128.0000 - fn: 4.0000 - accuracy: 0.9508 - precision: 0.9286 - recall: 0.9630 - auc: 0.9924 - prc: 0.9915 - val_loss: 4.4713 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.5335 - tp: 102.0000 - fp: 4.0000 - tn: 132.0000 - fn: 6.0000 - accuracy: 0.9590 - precision: 0.9623 - recall: 0.9444 - auc: 0.9923 - prc: 0.9914 - val_loss: 4.4130 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.4668 - tp: 107.0000 - fp: 4.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9795 - precision: 0.9640 - recall: 0.9907 - auc: 0.9966 - prc: 0.9954 - val_loss: 4.4004 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.4602 - tp: 103.0000 - fp: 4.0000 - tn: 132.0000 - fn: 5.0000 - accuracy: 0.9631 - precision: 0.9626 - recall: 0.9537 - auc: 0.9956 - prc: 0.9949 - val_loss: 4.3662 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.4347 - tp: 104.0000 - fp: 2.0000 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9754 - precision: 0.9811 - recall: 0.9630 - auc: 0.9949 - prc: 0.9944 - val_loss: 4.3477 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.3632 - tp: 108.0000 - fp: 2.0000 - tn: 134.0000 - fn: 0.0000e+00 - accuracy: 0.9918 - precision: 0.9818 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.3377 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.3822 - tp: 103.0000 - fp: 3.0000 - tn: 133.0000 - fn: 5.0000 - accuracy: 0.9672 - precision: 0.9717 - recall: 0.9537 - auc: 0.9965 - prc: 0.9961 - val_loss: 4.3166 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.3500 - tp: 104.0000 - fp: 1.0000 - tn: 135.0000 - fn: 4.0000 - accuracy: 0.9795 - precision: 0.9905 - recall: 0.9630 - auc: 0.9979 - prc: 0.9975 - val_loss: 4.2725 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.3039 - tp: 106.0000 - fp: 2.0000 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9836 - precision: 0.9815 - recall: 0.9815 - auc: 0.9988 - prc: 0.9986 - val_loss: 4.2504 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.3000 - tp: 105.0000 - fp: 5.0000 - tn: 131.0000 - fn: 3.0000 - accuracy: 0.9672 - precision: 0.9545 - recall: 0.9722 - auc: 0.9985 - prc: 0.9981 - val_loss: 4.2281 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.2819 - tp: 105.0000 - fp: 3.0000 - tn: 133.0000 - fn: 3.0000 - accuracy: 0.9754 - precision: 0.9722 - recall: 0.9722 - auc: 0.9971 - prc: 0.9963 - val_loss: 4.2415 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.2665 - tp: 103.0000 - fp: 1.0000 - tn: 135.0000 - fn: 5.0000 - accuracy: 0.9754 - precision: 0.9904 - recall: 0.9537 - auc: 0.9965 - prc: 0.9962 - val_loss: 4.1853 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.2043 - tp: 106.0000 - fp: 0.0000e+00 - tn: 136.0000 - fn: 2.0000 - accuracy: 0.9918 - precision: 1.0000 - recall: 0.9815 - auc: 0.9997 - prc: 0.9996 - val_loss: 4.1622 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.1961 - tp: 106.0000 - fp: 2.0000 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9836 - precision: 0.9815 - recall: 0.9815 - auc: 0.9988 - prc: 0.9985 - val_loss: 4.1363 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.2299 - tp: 105.0000 - fp: 3.0000 - tn: 133.0000 - fn: 3.0000 - accuracy: 0.9754 - precision: 0.9722 - recall: 0.9722 - auc: 0.9917 - prc: 0.9846 - val_loss: 4.1160 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.2126 - tp: 100.0000 - fp: 5.0000 - tn: 131.0000 - fn: 8.0000 - accuracy: 0.9467 - precision: 0.9524 - recall: 0.9259 - auc: 0.9928 - prc: 0.9915 - val_loss: 4.0946 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.1695 - tp: 105.0000 - fp: 4.0000 - tn: 132.0000 - fn: 3.0000 - accuracy: 0.9713 - precision: 0.9633 - recall: 0.9722 - auc: 0.9953 - prc: 0.9938 - val_loss: 4.0723 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.1088 - tp: 106.0000 - fp: 2.0000 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9836 - precision: 0.9815 - recall: 0.9815 - auc: 0.9984 - prc: 0.9981 - val_loss: 4.0501 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.0960 - tp: 107.0000 - fp: 5.0000 - tn: 131.0000 - fn: 1.0000 - accuracy: 0.9754 - precision: 0.9554 - recall: 0.9907 - auc: 0.9979 - prc: 0.9974 - val_loss: 4.0295 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.0818 - tp: 104.0000 - fp: 3.0000 - tn: 133.0000 - fn: 4.0000 - accuracy: 0.9713 - precision: 0.9720 - recall: 0.9630 - auc: 0.9974 - prc: 0.9967 - val_loss: 4.1301 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.0734 - tp: 101.0000 - fp: 3.0000 - tn: 133.0000 - fn: 7.0000 - accuracy: 0.9590 - precision: 0.9712 - recall: 0.9352 - auc: 0.9965 - prc: 0.9957 - val_loss: 3.9846 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.0240 - tp: 105.0000 - fp: 2.0000 - tn: 134.0000 - fn: 3.0000 - accuracy: 0.9795 - precision: 0.9813 - recall: 0.9722 - auc: 0.9986 - prc: 0.9983 - val_loss: 3.9622 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.0214 - tp: 104.0000 - fp: 2.0000 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9754 - precision: 0.9811 - recall: 0.9630 - auc: 0.9971 - prc: 0.9967 - val_loss: 3.9405 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.9598 - tp: 108.0000 - fp: 1.0000 - tn: 135.0000 - fn: 0.0000e+00 - accuracy: 0.9959 - precision: 0.9908 - recall: 1.0000 - auc: 0.9998 - prc: 0.9997 - val_loss: 3.9270 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.9381 - tp: 106.0000 - fp: 1.0000 - tn: 135.0000 - fn: 2.0000 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9815 - auc: 0.9997 - prc: 0.9996 - val_loss: 3.9006 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.9168 - tp: 106.0000 - fp: 0.0000e+00 - tn: 136.0000 - fn: 2.0000 - accuracy: 0.9918 - precision: 1.0000 - recall: 0.9815 - auc: 0.9996 - prc: 0.9995 - val_loss: 3.8766 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.8947 - tp: 107.0000 - fp: 2.0000 - tn: 134.0000 - fn: 1.0000 - accuracy: 0.9877 - precision: 0.9817 - recall: 0.9907 - auc: 0.9997 - prc: 0.9996 - val_loss: 3.8594 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.8922 - tp: 106.0000 - fp: 3.0000 - tn: 133.0000 - fn: 2.0000 - accuracy: 0.9795 - precision: 0.9725 - recall: 0.9815 - auc: 0.9985 - prc: 0.9981 - val_loss: 3.8338 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.8758 - tp: 106.0000 - fp: 3.0000 - tn: 133.0000 - fn: 2.0000 - accuracy: 0.9795 - precision: 0.9725 - recall: 0.9815 - auc: 0.9984 - prc: 0.9981 - val_loss: 3.8194 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.8588 - tp: 106.0000 - fp: 1.0000 - tn: 135.0000 - fn: 2.0000 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9815 - auc: 0.9979 - prc: 0.9976 - val_loss: 3.7918 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.8621 - tp: 103.0000 - fp: 2.0000 - tn: 134.0000 - fn: 5.0000 - accuracy: 0.9713 - precision: 0.9810 - recall: 0.9537 - auc: 0.9960 - prc: 0.9955 - val_loss: 3.7743 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 3.8158 - tp: 105.0000 - fp: 3.0000 - tn: 133.0000 - fn: 3.0000 - accuracy: 0.9754 - precision: 0.9722 - recall: 0.9722 - auc: 0.9982 - prc: 0.9979 - val_loss: 3.7777 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7775 - tp: 106.0000 - fp: 1.0000 - tn: 135.0000 - fn: 2.0000 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9815 - auc: 0.9993 - prc: 0.9991 - val_loss: 3.7370 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7736 - tp: 106.0000 - fp: 2.0000 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9836 - precision: 0.9815 - recall: 0.9815 - auc: 0.9978 - prc: 0.9976 - val_loss: 3.7086 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7770 - tp: 104.0000 - fp: 3.0000 - tn: 133.0000 - fn: 4.0000 - accuracy: 0.9713 - precision: 0.9720 - recall: 0.9630 - auc: 0.9963 - prc: 0.9956 - val_loss: 3.6881 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7538 - tp: 104.0000 - fp: 2.0000 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9754 - precision: 0.9811 - recall: 0.9630 - auc: 0.9924 - prc: 0.9939 - val_loss: 3.6679 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6937 - tp: 106.0000 - fp: 0.0000e+00 - tn: 136.0000 - fn: 2.0000 - accuracy: 0.9918 - precision: 1.0000 - recall: 0.9815 - auc: 0.9990 - prc: 0.9989 - val_loss: 3.6475 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6852 - tp: 106.0000 - fp: 2.0000 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9836 - precision: 0.9815 - recall: 0.9815 - auc: 0.9985 - prc: 0.9983 - val_loss: 3.6275 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6340 - tp: 107.0000 - fp: 0.0000e+00 - tn: 136.0000 - fn: 1.0000 - accuracy: 0.9959 - precision: 1.0000 - recall: 0.9907 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6063 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6109 - tp: 108.0000 - fp: 0.0000e+00 - tn: 136.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.5876 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6700 - tp: 105.0000 - fp: 4.0000 - tn: 132.0000 - fn: 3.0000 - accuracy: 0.9713 - precision: 0.9633 - recall: 0.9722 - auc: 0.9928 - prc: 0.9852 - val_loss: 3.5655 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6260 - tp: 104.0000 - fp: 3.0000 - tn: 133.0000 - fn: 4.0000 - accuracy: 0.9713 - precision: 0.9720 - recall: 0.9630 - auc: 0.9937 - prc: 0.9952 - val_loss: 3.5456 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.5896 - tp: 105.0000 - fp: 4.0000 - tn: 132.0000 - fn: 3.0000 - accuracy: 0.9713 - precision: 0.9633 - recall: 0.9722 - auc: 0.9980 - prc: 0.9975 - val_loss: 3.5281 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.5587 - tp: 105.0000 - fp: 1.0000 - tn: 135.0000 - fn: 3.0000 - accuracy: 0.9836 - precision: 0.9906 - recall: 0.9722 - auc: 0.9987 - prc: 0.9983 - val_loss: 3.5055 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6410 - tp: 102.0000 - fp: 6.0000 - tn: 130.0000 - fn: 6.0000 - accuracy: 0.9508 - precision: 0.9444 - recall: 0.9444 - auc: 0.9897 - prc: 0.9906 - val_loss: 3.4861 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.5088 - tp: 107.0000 - fp: 1.0000 - tn: 135.0000 - fn: 1.0000 - accuracy: 0.9918 - precision: 0.9907 - recall: 0.9907 - auc: 0.9995 - prc: 0.9994 - val_loss: 3.4664 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.4805 - tp: 107.0000 - fp: 1.0000 - tn: 135.0000 - fn: 1.0000 - accuracy: 0.9918 - precision: 0.9907 - recall: 0.9907 - auc: 0.9998 - prc: 0.9997 - val_loss: 3.4469 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.4570 - tp: 106.0000 - fp: 1.0000 - tn: 135.0000 - fn: 2.0000 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9815 - auc: 0.9999 - prc: 0.9998 - val_loss: 3.4266 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.5463 - tp: 102.0000 - fp: 6.0000 - tn: 130.0000 - fn: 6.0000 - accuracy: 0.9508 - precision: 0.9444 - recall: 0.9444 - auc: 0.9886 - prc: 0.9896 - val_loss: 3.4072 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.4775 - tp: 103.0000 - fp: 3.0000 - tn: 133.0000 - fn: 5.0000 - accuracy: 0.9672 - precision: 0.9717 - recall: 0.9537 - auc: 0.9964 - prc: 0.9953 - val_loss: 3.3951 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.4655 - tp: 104.0000 - fp: 2.0000 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9754 - precision: 0.9811 - recall: 0.9630 - auc: 0.9924 - prc: 0.9936 - val_loss: 3.3690 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.4316 - tp: 104.0000 - fp: 4.0000 - tn: 132.0000 - fn: 4.0000 - accuracy: 0.9672 - precision: 0.9630 - recall: 0.9630 - auc: 0.9973 - prc: 0.9968 - val_loss: 3.3501 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Archivo: e_coli_driams_b_2000_20000Da_v2 (1).csv Bacteria: Ceftriaxone\n",
      "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 5984, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_52 (Activation)  (None, 5984, 64)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 2984, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_53 (Activation)  (None, 2984, 128)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 1488, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_54 (Activation)  (None, 1488, 256)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 740, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 740, 256)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 94720)             0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 94720)             0         \n",
      "                                                                 \n",
      " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
      "                                                                 \n",
      " fully_connected_1 (Dense)   (None, 64)                16448     \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 64)                4160      \n",
      "                                                                 \n",
      " OUT_Layer (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,839,105\n",
      "Trainable params: 24,837,697\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 3s 63ms/step - loss: 7.0135 - tp: 14.0000 - fp: 26.0000 - tn: 129.0000 - fn: 27.0000 - accuracy: 0.7296 - precision: 0.3500 - recall: 0.3415 - auc: 0.6391 - prc: 0.3259 - val_loss: 6.7951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2788 - val_prc: 0.1596 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.7440 - tp: 8.0000 - fp: 21.0000 - tn: 100.0000 - fn: 24.0000 - accuracy: 0.7059 - precision: 0.2759 - recall: 0.2500 - auc: 0.5825 - prc: 0.2356 - val_loss: 6.7205 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.2353 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.5199 - tp: 4.0000 - fp: 5.0000 - tn: 116.0000 - fn: 28.0000 - accuracy: 0.7843 - precision: 0.4444 - recall: 0.1250 - auc: 0.7065 - prc: 0.3882 - val_loss: 6.6478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5288 - val_prc: 0.2479 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5063 - tp: 10.0000 - fp: 10.0000 - tn: 111.0000 - fn: 22.0000 - accuracy: 0.7908 - precision: 0.5000 - recall: 0.3125 - auc: 0.6819 - prc: 0.3580 - val_loss: 6.5678 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4615 - val_prc: 0.2057 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4701 - tp: 15.0000 - fp: 26.0000 - tn: 95.0000 - fn: 17.0000 - accuracy: 0.7190 - precision: 0.3659 - recall: 0.4688 - auc: 0.7229 - prc: 0.3716 - val_loss: 6.4870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6538 - val_prc: 0.3077 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3702 - tp: 2.0000 - fp: 4.0000 - tn: 117.0000 - fn: 30.0000 - accuracy: 0.7778 - precision: 0.3333 - recall: 0.0625 - auc: 0.7198 - prc: 0.3772 - val_loss: 6.4274 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.2919 - tp: 8.0000 - fp: 6.0000 - tn: 115.0000 - fn: 24.0000 - accuracy: 0.8039 - precision: 0.5714 - recall: 0.2500 - auc: 0.7543 - prc: 0.4510 - val_loss: 6.3719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3558 - val_prc: 0.1740 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.2497 - tp: 8.0000 - fp: 13.0000 - tn: 108.0000 - fn: 24.0000 - accuracy: 0.7582 - precision: 0.3810 - recall: 0.2500 - auc: 0.7421 - prc: 0.4208 - val_loss: 6.3531 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.1511 - tp: 12.0000 - fp: 7.0000 - tn: 114.0000 - fn: 20.0000 - accuracy: 0.8235 - precision: 0.6316 - recall: 0.3750 - auc: 0.7944 - prc: 0.4716 - val_loss: 6.3121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6635 - val_prc: 0.3236 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.0881 - tp: 9.0000 - fp: 7.0000 - tn: 114.0000 - fn: 23.0000 - accuracy: 0.8039 - precision: 0.5625 - recall: 0.2812 - auc: 0.8128 - prc: 0.5347 - val_loss: 6.2439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6346 - val_prc: 0.6194 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.1454 - tp: 7.0000 - fp: 12.0000 - tn: 109.0000 - fn: 25.0000 - accuracy: 0.7582 - precision: 0.3684 - recall: 0.2188 - auc: 0.7136 - prc: 0.3883 - val_loss: 6.1991 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6250 - val_prc: 0.3537 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.9769 - tp: 17.0000 - fp: 8.0000 - tn: 113.0000 - fn: 15.0000 - accuracy: 0.8497 - precision: 0.6800 - recall: 0.5312 - auc: 0.8536 - prc: 0.5720 - val_loss: 6.1264 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827 - val_prc: 0.3512 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.9726 - tp: 12.0000 - fp: 10.0000 - tn: 111.0000 - fn: 20.0000 - accuracy: 0.8039 - precision: 0.5455 - recall: 0.3750 - auc: 0.8113 - prc: 0.5663 - val_loss: 6.1146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827 - val_prc: 0.3577 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9396 - tp: 9.0000 - fp: 7.0000 - tn: 114.0000 - fn: 23.0000 - accuracy: 0.8039 - precision: 0.5625 - recall: 0.2812 - auc: 0.8103 - prc: 0.4791 - val_loss: 6.1330 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7692 - val_prc: 0.5346 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.9027 - tp: 14.0000 - fp: 11.0000 - tn: 110.0000 - fn: 18.0000 - accuracy: 0.8105 - precision: 0.5600 - recall: 0.4375 - auc: 0.8142 - prc: 0.5818 - val_loss: 6.0339 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7115 - val_prc: 0.3181 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.8198 - tp: 13.0000 - fp: 4.0000 - tn: 117.0000 - fn: 19.0000 - accuracy: 0.8497 - precision: 0.7647 - recall: 0.4062 - auc: 0.8465 - prc: 0.6606 - val_loss: 6.0630 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6442 - val_prc: 0.3531 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8138 - tp: 18.0000 - fp: 8.0000 - tn: 113.0000 - fn: 14.0000 - accuracy: 0.8562 - precision: 0.6923 - recall: 0.5625 - auc: 0.8266 - prc: 0.5783 - val_loss: 5.9535 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4519 - val_prc: 0.4024 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.8051 - tp: 9.0000 - fp: 10.0000 - tn: 111.0000 - fn: 23.0000 - accuracy: 0.7843 - precision: 0.4737 - recall: 0.2812 - auc: 0.8215 - prc: 0.5391 - val_loss: 6.0180 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6442 - val_prc: 0.3029 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7056 - tp: 14.0000 - fp: 6.0000 - tn: 115.0000 - fn: 18.0000 - accuracy: 0.8431 - precision: 0.7000 - recall: 0.4375 - auc: 0.8552 - prc: 0.6709 - val_loss: 5.9183 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6538 - val_prc: 0.5070 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.6646 - tp: 17.0000 - fp: 8.0000 - tn: 113.0000 - fn: 15.0000 - accuracy: 0.8497 - precision: 0.6800 - recall: 0.5312 - auc: 0.8764 - prc: 0.6626 - val_loss: 5.8492 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6346 - val_prc: 0.2910 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6645 - tp: 14.0000 - fp: 8.0000 - tn: 113.0000 - fn: 18.0000 - accuracy: 0.8301 - precision: 0.6364 - recall: 0.4375 - auc: 0.8252 - prc: 0.6211 - val_loss: 5.8225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5673 - val_prc: 0.2556 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.5417 - tp: 15.0000 - fp: 4.0000 - tn: 117.0000 - fn: 17.0000 - accuracy: 0.8627 - precision: 0.7895 - recall: 0.4688 - auc: 0.9157 - prc: 0.7538 - val_loss: 5.8412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.2636 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.5229 - tp: 17.0000 - fp: 12.0000 - tn: 109.0000 - fn: 15.0000 - accuracy: 0.8235 - precision: 0.5862 - recall: 0.5312 - auc: 0.9118 - prc: 0.7088 - val_loss: 5.7573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5096 - val_prc: 0.4219 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.4831 - tp: 20.0000 - fp: 6.0000 - tn: 115.0000 - fn: 12.0000 - accuracy: 0.8824 - precision: 0.7692 - recall: 0.6250 - auc: 0.9193 - prc: 0.7134 - val_loss: 5.7336 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5096 - val_prc: 0.3010 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.5026 - tp: 15.0000 - fp: 9.0000 - tn: 112.0000 - fn: 17.0000 - accuracy: 0.8301 - precision: 0.6250 - recall: 0.4688 - auc: 0.8803 - prc: 0.6933 - val_loss: 5.7006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.2331 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.4744 - tp: 16.0000 - fp: 9.0000 - tn: 112.0000 - fn: 16.0000 - accuracy: 0.8366 - precision: 0.6400 - recall: 0.5000 - auc: 0.8803 - prc: 0.6706 - val_loss: 5.7091 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5000 - val_prc: 0.4166 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.4115 - tp: 14.0000 - fp: 4.0000 - tn: 117.0000 - fn: 18.0000 - accuracy: 0.8562 - precision: 0.7778 - recall: 0.4375 - auc: 0.9046 - prc: 0.7356 - val_loss: 5.7595 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5294 - val_precision: 0.1667 - val_recall: 0.2500 - val_auc: 0.4904 - val_prc: 0.2105 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.3812 - tp: 18.0000 - fp: 6.0000 - tn: 115.0000 - fn: 14.0000 - accuracy: 0.8693 - precision: 0.7500 - recall: 0.5625 - auc: 0.8914 - prc: 0.7561 - val_loss: 5.6778 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5192 - val_prc: 0.4260 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.3250 - tp: 23.0000 - fp: 7.0000 - tn: 114.0000 - fn: 9.0000 - accuracy: 0.8954 - precision: 0.7667 - recall: 0.7188 - auc: 0.9264 - prc: 0.7532 - val_loss: 5.6257 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.4336 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.2519 - tp: 20.0000 - fp: 8.0000 - tn: 113.0000 - fn: 12.0000 - accuracy: 0.8693 - precision: 0.7143 - recall: 0.6250 - auc: 0.9514 - prc: 0.8349 - val_loss: 5.6019 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5385 - val_prc: 0.4336 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.2395 - tp: 22.0000 - fp: 8.0000 - tn: 113.0000 - fn: 10.0000 - accuracy: 0.8824 - precision: 0.7333 - recall: 0.6875 - auc: 0.9400 - prc: 0.8380 - val_loss: 5.5642 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5000 - val_prc: 0.4197 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.2527 - tp: 19.0000 - fp: 9.0000 - tn: 112.0000 - fn: 13.0000 - accuracy: 0.8562 - precision: 0.6786 - recall: 0.5938 - auc: 0.9109 - prc: 0.7962 - val_loss: 5.5289 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.4336 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.2352 - tp: 20.0000 - fp: 10.0000 - tn: 111.0000 - fn: 12.0000 - accuracy: 0.8562 - precision: 0.6667 - recall: 0.6250 - auc: 0.9084 - prc: 0.7819 - val_loss: 5.5201 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5577 - val_prc: 0.4440 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.1789 - tp: 24.0000 - fp: 7.0000 - tn: 114.0000 - fn: 8.0000 - accuracy: 0.9020 - precision: 0.7742 - recall: 0.7500 - auc: 0.9379 - prc: 0.7870 - val_loss: 5.5329 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.5192 - val_prc: 0.4300 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.1254 - tp: 23.0000 - fp: 8.0000 - tn: 113.0000 - fn: 9.0000 - accuracy: 0.8889 - precision: 0.7419 - recall: 0.7188 - auc: 0.9471 - prc: 0.8544 - val_loss: 5.5870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5096 - val_prc: 0.4226 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.1756 - tp: 18.0000 - fp: 9.0000 - tn: 112.0000 - fn: 14.0000 - accuracy: 0.8497 - precision: 0.6667 - recall: 0.5625 - auc: 0.9038 - prc: 0.7442 - val_loss: 5.5132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5577 - val_prc: 0.4434 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.1570 - tp: 17.0000 - fp: 5.0000 - tn: 116.0000 - fn: 15.0000 - accuracy: 0.8693 - precision: 0.7727 - recall: 0.5312 - auc: 0.9257 - prc: 0.7940 - val_loss: 5.8748 - val_tp: 3.0000 - val_fp: 10.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.3529 - val_precision: 0.2308 - val_recall: 0.7500 - val_auc: 0.6346 - val_prc: 0.5347 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.0146 - tp: 25.0000 - fp: 7.0000 - tn: 114.0000 - fn: 7.0000 - accuracy: 0.9085 - precision: 0.7812 - recall: 0.7812 - auc: 0.9678 - prc: 0.8978 - val_loss: 5.4948 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6471 - val_precision: 0.3333 - val_recall: 0.5000 - val_auc: 0.5769 - val_prc: 0.4589 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.0037 - tp: 26.0000 - fp: 4.0000 - tn: 117.0000 - fn: 6.0000 - accuracy: 0.9346 - precision: 0.8667 - recall: 0.8125 - auc: 0.9635 - prc: 0.8974 - val_loss: 5.4853 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.5882 - val_precision: 0.2857 - val_recall: 0.5000 - val_auc: 0.5962 - val_prc: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 4.9795 - tp: 22.0000 - fp: 3.0000 - tn: 118.0000 - fn: 10.0000 - accuracy: 0.9150 - precision: 0.8800 - recall: 0.6875 - auc: 0.9595 - prc: 0.8934 - val_loss: 5.5164 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6471 - val_precision: 0.3750 - val_recall: 0.7500 - val_auc: 0.6154 - val_prc: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 4.9476 - tp: 25.0000 - fp: 10.0000 - tn: 111.0000 - fn: 7.0000 - accuracy: 0.8889 - precision: 0.7143 - recall: 0.7812 - auc: 0.9666 - prc: 0.8987 - val_loss: 5.5228 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.5882 - val_precision: 0.2857 - val_recall: 0.5000 - val_auc: 0.6154 - val_prc: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 4.9801 - tp: 24.0000 - fp: 8.0000 - tn: 113.0000 - fn: 8.0000 - accuracy: 0.8954 - precision: 0.7500 - recall: 0.7500 - auc: 0.9419 - prc: 0.8656 - val_loss: 5.4728 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6471 - val_precision: 0.3333 - val_recall: 0.5000 - val_auc: 0.6154 - val_prc: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 4.9112 - tp: 25.0000 - fp: 6.0000 - tn: 115.0000 - fn: 7.0000 - accuracy: 0.9150 - precision: 0.8065 - recall: 0.7812 - auc: 0.9616 - prc: 0.9033 - val_loss: 5.5698 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6471 - val_precision: 0.3750 - val_recall: 0.7500 - val_auc: 0.5962 - val_prc: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 4.8982 - tp: 20.0000 - fp: 5.0000 - tn: 116.0000 - fn: 12.0000 - accuracy: 0.8889 - precision: 0.8000 - recall: 0.6250 - auc: 0.9640 - prc: 0.8722 - val_loss: 5.6034 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6471 - val_precision: 0.3750 - val_recall: 0.7500 - val_auc: 0.5673 - val_prc: 0.3287 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 4.8513 - tp: 23.0000 - fp: 2.0000 - tn: 119.0000 - fn: 9.0000 - accuracy: 0.9281 - precision: 0.9200 - recall: 0.7188 - auc: 0.9706 - prc: 0.9071 - val_loss: 5.7177 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5294 - val_precision: 0.3000 - val_recall: 0.7500 - val_auc: 0.5769 - val_prc: 0.4537 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 4.8438 - tp: 27.0000 - fp: 8.0000 - tn: 113.0000 - fn: 5.0000 - accuracy: 0.9150 - precision: 0.7714 - recall: 0.8438 - auc: 0.9725 - prc: 0.9146 - val_loss: 5.6427 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.5882 - val_precision: 0.3333 - val_recall: 0.7500 - val_auc: 0.5865 - val_prc: 0.4597 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 5984, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 5984, 64)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 2984, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 2984, 128)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 1488, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 1488, 256)         0         \n",
      "                                                                 \n",
      " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 740, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 740, 256)          0         \n",
      "                                                                 \n",
      " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 94720)             0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 94720)             0         \n",
      "                                                                 \n",
      " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
      "                                                                 \n",
      " fully_connected_1 (Dense)   (None, 64)                16448     \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 64)                4160      \n",
      "                                                                 \n",
      " OUT_Layer (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,839,105\n",
      "Trainable params: 24,837,697\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 60ms/step - loss: 7.0293 - tp: 48.0000 - fp: 50.0000 - tn: 118.0000 - fn: 68.0000 - accuracy: 0.5845 - precision: 0.4898 - recall: 0.4138 - auc: 0.6036 - prc: 0.4722 - val_loss: 6.8019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 6.6583 - tp: 68.0000 - fp: 43.0000 - tn: 91.0000 - fn: 39.0000 - accuracy: 0.6598 - precision: 0.6126 - recall: 0.6355 - auc: 0.7192 - prc: 0.6633 - val_loss: 6.6843 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.6661 - tp: 66.0000 - fp: 43.0000 - tn: 91.0000 - fn: 41.0000 - accuracy: 0.6515 - precision: 0.6055 - recall: 0.6168 - auc: 0.6831 - prc: 0.6085 - val_loss: 6.6263 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 6.4334 - tp: 75.0000 - fp: 41.0000 - tn: 93.0000 - fn: 32.0000 - accuracy: 0.6971 - precision: 0.6466 - recall: 0.7009 - auc: 0.7713 - prc: 0.7113 - val_loss: 6.6153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 6.3136 - tp: 74.0000 - fp: 34.0000 - tn: 100.0000 - fn: 33.0000 - accuracy: 0.7220 - precision: 0.6852 - recall: 0.6916 - auc: 0.8074 - prc: 0.7241 - val_loss: 6.6828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.2533 - tp: 78.0000 - fp: 32.0000 - tn: 102.0000 - fn: 29.0000 - accuracy: 0.7469 - precision: 0.7091 - recall: 0.7290 - auc: 0.7958 - prc: 0.7350 - val_loss: 6.3957 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 6.1077 - tp: 81.0000 - fp: 28.0000 - tn: 106.0000 - fn: 26.0000 - accuracy: 0.7759 - precision: 0.7431 - recall: 0.7570 - auc: 0.8475 - prc: 0.8234 - val_loss: 6.2787 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 6.0467 - tp: 80.0000 - fp: 40.0000 - tn: 94.0000 - fn: 27.0000 - accuracy: 0.7220 - precision: 0.6667 - recall: 0.7477 - auc: 0.8371 - prc: 0.7660 - val_loss: 6.3632 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 5.9258 - tp: 86.0000 - fp: 28.0000 - tn: 106.0000 - fn: 21.0000 - accuracy: 0.7967 - precision: 0.7544 - recall: 0.8037 - auc: 0.8842 - prc: 0.8584 - val_loss: 6.4529 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 5.8909 - tp: 79.0000 - fp: 27.0000 - tn: 107.0000 - fn: 28.0000 - accuracy: 0.7718 - precision: 0.7453 - recall: 0.7383 - auc: 0.8641 - prc: 0.8291 - val_loss: 6.2045 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.8020 - tp: 85.0000 - fp: 31.0000 - tn: 103.0000 - fn: 22.0000 - accuracy: 0.7801 - precision: 0.7328 - recall: 0.7944 - auc: 0.8770 - prc: 0.8283 - val_loss: 6.1712 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 27.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.7222 - tp: 82.0000 - fp: 24.0000 - tn: 110.0000 - fn: 25.0000 - accuracy: 0.7967 - precision: 0.7736 - recall: 0.7664 - auc: 0.8902 - prc: 0.8492 - val_loss: 5.9008 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.6364 - tp: 93.0000 - fp: 24.0000 - tn: 110.0000 - fn: 14.0000 - accuracy: 0.8423 - precision: 0.7949 - recall: 0.8692 - auc: 0.9092 - prc: 0.8787 - val_loss: 5.8647 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 5.5588 - tp: 87.0000 - fp: 19.0000 - tn: 115.0000 - fn: 20.0000 - accuracy: 0.8382 - precision: 0.8208 - recall: 0.8131 - auc: 0.9194 - prc: 0.8927 - val_loss: 5.8670 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 16.0000 - val_accuracy: 0.4074 - val_precision: 1.0000 - val_recall: 0.4074 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.5269 - tp: 84.0000 - fp: 22.0000 - tn: 112.0000 - fn: 23.0000 - accuracy: 0.8133 - precision: 0.7925 - recall: 0.7850 - auc: 0.9103 - prc: 0.8908 - val_loss: 5.7411 - val_tp: 22.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 5.0000 - val_accuracy: 0.8148 - val_precision: 1.0000 - val_recall: 0.8148 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.3994 - tp: 92.0000 - fp: 11.0000 - tn: 123.0000 - fn: 15.0000 - accuracy: 0.8921 - precision: 0.8932 - recall: 0.8598 - auc: 0.9465 - prc: 0.9379 - val_loss: 5.4736 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.4474 - tp: 89.0000 - fp: 21.0000 - tn: 113.0000 - fn: 18.0000 - accuracy: 0.8382 - precision: 0.8091 - recall: 0.8318 - auc: 0.9036 - prc: 0.8508 - val_loss: 5.3632 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 5.3525 - tp: 94.0000 - fp: 24.0000 - tn: 110.0000 - fn: 13.0000 - accuracy: 0.8465 - precision: 0.7966 - recall: 0.8785 - auc: 0.9267 - prc: 0.8866 - val_loss: 5.5779 - val_tp: 22.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 5.0000 - val_accuracy: 0.8148 - val_precision: 1.0000 - val_recall: 0.8148 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.2719 - tp: 90.0000 - fp: 17.0000 - tn: 117.0000 - fn: 17.0000 - accuracy: 0.8589 - precision: 0.8411 - recall: 0.8411 - auc: 0.9410 - prc: 0.9248 - val_loss: 5.2534 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.2159 - tp: 96.0000 - fp: 15.0000 - tn: 119.0000 - fn: 11.0000 - accuracy: 0.8921 - precision: 0.8649 - recall: 0.8972 - auc: 0.9503 - prc: 0.9385 - val_loss: 5.1089 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 5.3013 - tp: 90.0000 - fp: 26.0000 - tn: 108.0000 - fn: 17.0000 - accuracy: 0.8216 - precision: 0.7759 - recall: 0.8411 - auc: 0.9036 - prc: 0.8572 - val_loss: 5.2040 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 5.1351 - tp: 92.0000 - fp: 22.0000 - tn: 112.0000 - fn: 15.0000 - accuracy: 0.8465 - precision: 0.8070 - recall: 0.8598 - auc: 0.9467 - prc: 0.9309 - val_loss: 5.1530 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.0420 - tp: 95.0000 - fp: 16.0000 - tn: 118.0000 - fn: 12.0000 - accuracy: 0.8838 - precision: 0.8559 - recall: 0.8879 - auc: 0.9644 - prc: 0.9538 - val_loss: 5.0777 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 5.0087 - tp: 96.0000 - fp: 13.0000 - tn: 121.0000 - fn: 11.0000 - accuracy: 0.9004 - precision: 0.8807 - recall: 0.8972 - auc: 0.9627 - prc: 0.9440 - val_loss: 4.8539 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.9429 - tp: 101.0000 - fp: 13.0000 - tn: 121.0000 - fn: 6.0000 - accuracy: 0.9212 - precision: 0.8860 - recall: 0.9439 - auc: 0.9740 - prc: 0.9682 - val_loss: 4.9194 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.9909 - tp: 89.0000 - fp: 15.0000 - tn: 119.0000 - fn: 18.0000 - accuracy: 0.8631 - precision: 0.8558 - recall: 0.8318 - auc: 0.9478 - prc: 0.9273 - val_loss: 5.1034 - val_tp: 22.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 5.0000 - val_accuracy: 0.8148 - val_precision: 1.0000 - val_recall: 0.8148 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.9282 - tp: 93.0000 - fp: 14.0000 - tn: 120.0000 - fn: 14.0000 - accuracy: 0.8838 - precision: 0.8692 - recall: 0.8692 - auc: 0.9518 - prc: 0.9314 - val_loss: 4.8335 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.8683 - tp: 97.0000 - fp: 13.0000 - tn: 121.0000 - fn: 10.0000 - accuracy: 0.9046 - precision: 0.8818 - recall: 0.9065 - auc: 0.9595 - prc: 0.9421 - val_loss: 4.7475 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.8339 - tp: 99.0000 - fp: 17.0000 - tn: 117.0000 - fn: 8.0000 - accuracy: 0.8963 - precision: 0.8534 - recall: 0.9252 - auc: 0.9639 - prc: 0.9548 - val_loss: 4.6964 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 4.7806 - tp: 95.0000 - fp: 8.0000 - tn: 126.0000 - fn: 12.0000 - accuracy: 0.9170 - precision: 0.9223 - recall: 0.8879 - auc: 0.9686 - prc: 0.9565 - val_loss: 4.7121 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.7506 - tp: 94.0000 - fp: 9.0000 - tn: 125.0000 - fn: 13.0000 - accuracy: 0.9087 - precision: 0.9126 - recall: 0.8785 - auc: 0.9703 - prc: 0.9663 - val_loss: 4.6042 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.6831 - tp: 98.0000 - fp: 9.0000 - tn: 125.0000 - fn: 9.0000 - accuracy: 0.9253 - precision: 0.9159 - recall: 0.9159 - auc: 0.9760 - prc: 0.9660 - val_loss: 4.5010 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.6743 - tp: 98.0000 - fp: 11.0000 - tn: 123.0000 - fn: 9.0000 - accuracy: 0.9170 - precision: 0.8991 - recall: 0.9159 - auc: 0.9731 - prc: 0.9652 - val_loss: 4.6128 - val_tp: 26.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.9630 - val_precision: 1.0000 - val_recall: 0.9630 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.5852 - tp: 100.0000 - fp: 6.0000 - tn: 128.0000 - fn: 7.0000 - accuracy: 0.9461 - precision: 0.9434 - recall: 0.9346 - auc: 0.9865 - prc: 0.9836 - val_loss: 4.4401 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.5706 - tp: 99.0000 - fp: 10.0000 - tn: 124.0000 - fn: 8.0000 - accuracy: 0.9253 - precision: 0.9083 - recall: 0.9252 - auc: 0.9823 - prc: 0.9792 - val_loss: 4.4505 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.4934 - tp: 100.0000 - fp: 9.0000 - tn: 125.0000 - fn: 7.0000 - accuracy: 0.9336 - precision: 0.9174 - recall: 0.9346 - auc: 0.9911 - prc: 0.9889 - val_loss: 4.3785 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.4783 - tp: 99.0000 - fp: 6.0000 - tn: 128.0000 - fn: 8.0000 - accuracy: 0.9419 - precision: 0.9429 - recall: 0.9252 - auc: 0.9894 - prc: 0.9868 - val_loss: 4.3496 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.4892 - tp: 100.0000 - fp: 13.0000 - tn: 121.0000 - fn: 7.0000 - accuracy: 0.9170 - precision: 0.8850 - recall: 0.9346 - auc: 0.9831 - prc: 0.9800 - val_loss: 4.3462 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.4268 - tp: 102.0000 - fp: 8.0000 - tn: 126.0000 - fn: 5.0000 - accuracy: 0.9461 - precision: 0.9273 - recall: 0.9533 - auc: 0.9847 - prc: 0.9777 - val_loss: 4.3508 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 4.3463 - tp: 107.0000 - fp: 6.0000 - tn: 128.0000 - fn: 0.0000e+00 - accuracy: 0.9751 - precision: 0.9469 - recall: 1.0000 - auc: 0.9944 - prc: 0.9926 - val_loss: 4.2650 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.3612 - tp: 103.0000 - fp: 5.0000 - tn: 129.0000 - fn: 4.0000 - accuracy: 0.9627 - precision: 0.9537 - recall: 0.9626 - auc: 0.9880 - prc: 0.9868 - val_loss: 4.2652 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.3113 - tp: 102.0000 - fp: 4.0000 - tn: 130.0000 - fn: 5.0000 - accuracy: 0.9627 - precision: 0.9623 - recall: 0.9533 - auc: 0.9925 - prc: 0.9897 - val_loss: 4.2406 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.3184 - tp: 102.0000 - fp: 6.0000 - tn: 128.0000 - fn: 5.0000 - accuracy: 0.9544 - precision: 0.9444 - recall: 0.9533 - auc: 0.9814 - prc: 0.9775 - val_loss: 4.2226 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.2719 - tp: 99.0000 - fp: 4.0000 - tn: 130.0000 - fn: 8.0000 - accuracy: 0.9502 - precision: 0.9612 - recall: 0.9252 - auc: 0.9886 - prc: 0.9741 - val_loss: 4.1560 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.3271 - tp: 98.0000 - fp: 13.0000 - tn: 121.0000 - fn: 9.0000 - accuracy: 0.9087 - precision: 0.8829 - recall: 0.9159 - auc: 0.9738 - prc: 0.9734 - val_loss: 4.1195 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 4.3550 - tp: 99.0000 - fp: 16.0000 - tn: 118.0000 - fn: 8.0000 - accuracy: 0.9004 - precision: 0.8609 - recall: 0.9252 - auc: 0.9614 - prc: 0.9356 - val_loss: 4.1183 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.2431 - tp: 95.0000 - fp: 8.0000 - tn: 126.0000 - fn: 12.0000 - accuracy: 0.9170 - precision: 0.9223 - recall: 0.8879 - auc: 0.9808 - prc: 0.9753 - val_loss: 4.0734 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 4.3308 - tp: 98.0000 - fp: 20.0000 - tn: 114.0000 - fn: 9.0000 - accuracy: 0.8797 - precision: 0.8305 - recall: 0.9159 - auc: 0.9557 - prc: 0.9414 - val_loss: 4.0997 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.1466 - tp: 103.0000 - fp: 4.0000 - tn: 130.0000 - fn: 4.0000 - accuracy: 0.9668 - precision: 0.9626 - recall: 0.9626 - auc: 0.9896 - prc: 0.9859 - val_loss: 4.0577 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 4.1618 - tp: 100.0000 - fp: 12.0000 - tn: 122.0000 - fn: 7.0000 - accuracy: 0.9212 - precision: 0.8929 - recall: 0.9346 - auc: 0.9820 - prc: 0.9753 - val_loss: 4.0347 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.0942 - tp: 102.0000 - fp: 7.0000 - tn: 127.0000 - fn: 5.0000 - accuracy: 0.9502 - precision: 0.9358 - recall: 0.9533 - auc: 0.9930 - prc: 0.9916 - val_loss: 3.9959 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.0579 - tp: 101.0000 - fp: 6.0000 - tn: 128.0000 - fn: 6.0000 - accuracy: 0.9502 - precision: 0.9439 - recall: 0.9439 - auc: 0.9937 - prc: 0.9924 - val_loss: 3.9369 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 4.0566 - tp: 101.0000 - fp: 8.0000 - tn: 126.0000 - fn: 6.0000 - accuracy: 0.9419 - precision: 0.9266 - recall: 0.9439 - auc: 0.9897 - prc: 0.9886 - val_loss: 3.9439 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 4.0386 - tp: 100.0000 - fp: 7.0000 - tn: 127.0000 - fn: 7.0000 - accuracy: 0.9419 - precision: 0.9346 - recall: 0.9346 - auc: 0.9855 - prc: 0.9863 - val_loss: 3.9327 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.9437 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9983 - prc: 0.9981 - val_loss: 3.8776 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.9295 - tp: 106.0000 - fp: 4.0000 - tn: 130.0000 - fn: 1.0000 - accuracy: 0.9793 - precision: 0.9636 - recall: 0.9907 - auc: 0.9970 - prc: 0.9961 - val_loss: 3.8494 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.9058 - tp: 105.0000 - fp: 5.0000 - tn: 129.0000 - fn: 2.0000 - accuracy: 0.9710 - precision: 0.9545 - recall: 0.9813 - auc: 0.9971 - prc: 0.9964 - val_loss: 3.8279 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.8843 - tp: 102.0000 - fp: 4.0000 - tn: 130.0000 - fn: 5.0000 - accuracy: 0.9627 - precision: 0.9623 - recall: 0.9533 - auc: 0.9963 - prc: 0.9956 - val_loss: 3.8027 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 3.8626 - tp: 106.0000 - fp: 4.0000 - tn: 130.0000 - fn: 1.0000 - accuracy: 0.9793 - precision: 0.9636 - recall: 0.9907 - auc: 0.9959 - prc: 0.9947 - val_loss: 3.8037 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 3.8698 - tp: 104.0000 - fp: 5.0000 - tn: 129.0000 - fn: 3.0000 - accuracy: 0.9668 - precision: 0.9541 - recall: 0.9720 - auc: 0.9888 - prc: 0.9883 - val_loss: 4.0810 - val_tp: 24.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 3.0000 - val_accuracy: 0.8889 - val_precision: 1.0000 - val_recall: 0.8889 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 3.8291 - tp: 104.0000 - fp: 5.0000 - tn: 129.0000 - fn: 3.0000 - accuracy: 0.9668 - precision: 0.9541 - recall: 0.9720 - auc: 0.9953 - prc: 0.9942 - val_loss: 3.8183 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7993 - tp: 103.0000 - fp: 0.0000e+00 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9834 - precision: 1.0000 - recall: 0.9626 - auc: 0.9988 - prc: 0.9986 - val_loss: 3.7427 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7749 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9992 - prc: 0.9990 - val_loss: 3.7355 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 3.7884 - tp: 104.0000 - fp: 5.0000 - tn: 129.0000 - fn: 3.0000 - accuracy: 0.9668 - precision: 0.9541 - recall: 0.9720 - auc: 0.9979 - prc: 0.9974 - val_loss: 3.7404 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 3.7881 - tp: 103.0000 - fp: 0.0000e+00 - tn: 134.0000 - fn: 4.0000 - accuracy: 0.9834 - precision: 1.0000 - recall: 0.9626 - auc: 0.9993 - prc: 0.9991 - val_loss: 3.7438 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7731 - tp: 106.0000 - fp: 3.0000 - tn: 131.0000 - fn: 1.0000 - accuracy: 0.9834 - precision: 0.9725 - recall: 0.9907 - auc: 0.9991 - prc: 0.9990 - val_loss: 3.7334 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7529 - tp: 106.0000 - fp: 3.0000 - tn: 131.0000 - fn: 1.0000 - accuracy: 0.9834 - precision: 0.9725 - recall: 0.9907 - auc: 0.9995 - prc: 0.9994 - val_loss: 3.7252 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7899 - tp: 103.0000 - fp: 3.0000 - tn: 131.0000 - fn: 4.0000 - accuracy: 0.9710 - precision: 0.9717 - recall: 0.9626 - auc: 0.9968 - prc: 0.9962 - val_loss: 3.7229 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7552 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9990 - prc: 0.9987 - val_loss: 3.7204 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.7575 - tp: 104.0000 - fp: 2.0000 - tn: 132.0000 - fn: 3.0000 - accuracy: 0.9793 - precision: 0.9811 - recall: 0.9720 - auc: 0.9987 - prc: 0.9984 - val_loss: 3.7168 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7492 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9998 - prc: 0.9997 - val_loss: 3.7138 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.7332 - tp: 106.0000 - fp: 0.0000e+00 - tn: 134.0000 - fn: 1.0000 - accuracy: 0.9959 - precision: 1.0000 - recall: 0.9907 - auc: 0.9999 - prc: 0.9999 - val_loss: 3.7119 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7571 - tp: 103.0000 - fp: 3.0000 - tn: 131.0000 - fn: 4.0000 - accuracy: 0.9710 - precision: 0.9717 - recall: 0.9626 - auc: 0.9987 - prc: 0.9984 - val_loss: 3.7057 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.7590 - tp: 107.0000 - fp: 6.0000 - tn: 128.0000 - fn: 0.0000e+00 - accuracy: 0.9751 - precision: 0.9469 - recall: 1.0000 - auc: 0.9995 - prc: 0.9994 - val_loss: 3.7018 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 3.7561 - tp: 104.0000 - fp: 3.0000 - tn: 131.0000 - fn: 3.0000 - accuracy: 0.9751 - precision: 0.9720 - recall: 0.9720 - auc: 0.9983 - prc: 0.9979 - val_loss: 3.7025 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7485 - tp: 105.0000 - fp: 5.0000 - tn: 129.0000 - fn: 2.0000 - accuracy: 0.9710 - precision: 0.9545 - recall: 0.9813 - auc: 0.9986 - prc: 0.9983 - val_loss: 3.7010 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 3.7241 - tp: 106.0000 - fp: 1.0000 - tn: 133.0000 - fn: 1.0000 - accuracy: 0.9917 - precision: 0.9907 - recall: 0.9907 - auc: 0.9997 - prc: 0.9997 - val_loss: 3.7026 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7455 - tp: 105.0000 - fp: 4.0000 - tn: 130.0000 - fn: 2.0000 - accuracy: 0.9751 - precision: 0.9633 - recall: 0.9813 - auc: 0.9981 - prc: 0.9976 - val_loss: 3.7007 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7260 - tp: 107.0000 - fp: 2.0000 - tn: 132.0000 - fn: 0.0000e+00 - accuracy: 0.9917 - precision: 0.9817 - recall: 1.0000 - auc: 0.9996 - prc: 0.9995 - val_loss: 3.6903 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 3.7242 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9998 - prc: 0.9997 - val_loss: 3.6920 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7047 - tp: 106.0000 - fp: 0.0000e+00 - tn: 134.0000 - fn: 1.0000 - accuracy: 0.9959 - precision: 1.0000 - recall: 0.9907 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6887 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7243 - tp: 105.0000 - fp: 2.0000 - tn: 132.0000 - fn: 2.0000 - accuracy: 0.9834 - precision: 0.9813 - recall: 0.9813 - auc: 0.9991 - prc: 0.9988 - val_loss: 3.6838 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7291 - tp: 106.0000 - fp: 3.0000 - tn: 131.0000 - fn: 1.0000 - accuracy: 0.9834 - precision: 0.9725 - recall: 0.9907 - auc: 0.9977 - prc: 0.9970 - val_loss: 3.6825 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7260 - tp: 104.0000 - fp: 3.0000 - tn: 131.0000 - fn: 3.0000 - accuracy: 0.9751 - precision: 0.9720 - recall: 0.9720 - auc: 0.9983 - prc: 0.9978 - val_loss: 3.6767 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.7044 - tp: 105.0000 - fp: 2.0000 - tn: 132.0000 - fn: 2.0000 - accuracy: 0.9834 - precision: 0.9813 - recall: 0.9813 - auc: 0.9995 - prc: 0.9994 - val_loss: 3.6733 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6867 - tp: 107.0000 - fp: 1.0000 - tn: 133.0000 - fn: 0.0000e+00 - accuracy: 0.9959 - precision: 0.9907 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6719 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.7111 - tp: 105.0000 - fp: 2.0000 - tn: 132.0000 - fn: 2.0000 - accuracy: 0.9834 - precision: 0.9813 - recall: 0.9813 - auc: 0.9984 - prc: 0.9979 - val_loss: 3.6688 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.7050 - tp: 105.0000 - fp: 1.0000 - tn: 133.0000 - fn: 2.0000 - accuracy: 0.9876 - precision: 0.9906 - recall: 0.9813 - auc: 0.9990 - prc: 0.9988 - val_loss: 3.6644 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.7159 - tp: 106.0000 - fp: 4.0000 - tn: 130.0000 - fn: 1.0000 - accuracy: 0.9793 - precision: 0.9636 - recall: 0.9907 - auc: 0.9976 - prc: 0.9968 - val_loss: 3.6637 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6975 - tp: 106.0000 - fp: 1.0000 - tn: 133.0000 - fn: 1.0000 - accuracy: 0.9917 - precision: 0.9907 - recall: 0.9907 - auc: 0.9991 - prc: 0.9988 - val_loss: 3.6576 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6771 - tp: 107.0000 - fp: 2.0000 - tn: 132.0000 - fn: 0.0000e+00 - accuracy: 0.9917 - precision: 0.9817 - recall: 1.0000 - auc: 0.9999 - prc: 0.9999 - val_loss: 3.6559 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6804 - tp: 107.0000 - fp: 2.0000 - tn: 132.0000 - fn: 0.0000e+00 - accuracy: 0.9917 - precision: 0.9817 - recall: 1.0000 - auc: 0.9999 - prc: 0.9999 - val_loss: 3.6537 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6879 - tp: 105.0000 - fp: 0.0000e+00 - tn: 134.0000 - fn: 2.0000 - accuracy: 0.9917 - precision: 1.0000 - recall: 0.9813 - auc: 0.9997 - prc: 0.9997 - val_loss: 3.6494 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6773 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9996 - prc: 0.9995 - val_loss: 3.6449 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6725 - tp: 106.0000 - fp: 1.0000 - tn: 133.0000 - fn: 1.0000 - accuracy: 0.9917 - precision: 0.9907 - recall: 0.9907 - auc: 0.9996 - prc: 0.9995 - val_loss: 3.6425 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 3.6781 - tp: 106.0000 - fp: 3.0000 - tn: 131.0000 - fn: 1.0000 - accuracy: 0.9834 - precision: 0.9725 - recall: 0.9907 - auc: 0.9995 - prc: 0.9994 - val_loss: 3.6404 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.6670 - tp: 107.0000 - fp: 2.0000 - tn: 132.0000 - fn: 0.0000e+00 - accuracy: 0.9917 - precision: 0.9817 - recall: 1.0000 - auc: 0.9997 - prc: 0.9996 - val_loss: 3.6388 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 3.6700 - tp: 105.0000 - fp: 2.0000 - tn: 132.0000 - fn: 2.0000 - accuracy: 0.9834 - precision: 0.9813 - recall: 0.9813 - auc: 0.9992 - prc: 0.9991 - val_loss: 3.6346 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 3.6592 - tp: 106.0000 - fp: 2.0000 - tn: 132.0000 - fn: 1.0000 - accuracy: 0.9876 - precision: 0.9815 - recall: 0.9907 - auc: 0.9996 - prc: 0.9995 - val_loss: 3.6302 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 3.6519 - tp: 107.0000 - fp: 4.0000 - tn: 130.0000 - fn: 0.0000e+00 - accuracy: 0.9834 - precision: 0.9640 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6311 - val_tp: 27.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00 - val_prc: 1.0000 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Deshabilitar GPU\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "#from keras.backend import expand_dims\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential,Model\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.layers import Activation, Dense, Conv1D, Flatten, MaxPooling1D, Dropout, BatchNormalization, SpatialDropout1D,Lambda,Input\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import gc\n",
    "from tensorflow.keras.losses import mse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "# Deshabilitar GPU en TensorFlow\n",
    "#tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def Crear_modelo(X_train_reshaped,y_train):\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.000001)\n",
    "    early_st = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "    n_timesteps = X_train_reshaped.shape[1] #\n",
    "    n_features  = X_train_reshaped.shape[2] #\n",
    "\n",
    "    model = Sequential(name=\"Modelo_s_aureus_ciprofloxacin\")\n",
    "    init_mode = 'normal'\n",
    "    model.add(Conv1D(filters=(64), kernel_size=(17), input_shape = (n_timesteps,n_features), name='Conv_1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_1\"))\n",
    "\n",
    "    model.add(Conv1D(filters=(128), kernel_size=(9),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name='Conv_2'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_2\"))\n",
    "\n",
    "    model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode,kernel_regularizer=regularizers.l2(0.0001),   name='Conv_3'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_3\"))\n",
    "\n",
    "    model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),   name='Conv_4'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_4\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.65))\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_0\"))\n",
    "    model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_1\"))\n",
    "    model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name=\"fully_connected_2\"))\n",
    "    model.add(Dense(n_features, activation='sigmoid', name=\"OUT_Layer\"))\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate=0.0001), loss = 'binary_crossentropy',  metrics=METRICS)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=10, verbose=1, validation_split=0.1, callbacks=[reduce_lr,early_st])\n",
    "    return model\n",
    "\n",
    "def normalizacion(X_train, X_test):\n",
    "    scaler=Normalizer(norm='max')\n",
    "    sc_X = scaler\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "\n",
    "    sample_size = X_train.shape[0] # numero de muestras en el set de datos\n",
    "    time_steps  = X_train.shape[1] # numero de atributos en el set de datos\n",
    "    input_dimension = 1            #\n",
    "\n",
    "    X_train_reshaped = X_train.reshape(sample_size,time_steps,input_dimension)\n",
    "    X_test_reshaped = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "    return X_train_reshaped,X_test_reshaped\n",
    "\n",
    "\n",
    "def entrenamiento_base(X_train, X_test, y_train, y_test):\n",
    "    X_train_reshaped,X_test_reshaped = normalizacion(X_train, X_test)\n",
    "    \n",
    "    model = Crear_modelo(X_train_reshaped,y_train)\n",
    "\n",
    "    y_pred  = model.predict(X_test_reshaped)\n",
    "    y_pred = (y_pred>0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "    return model,'Entrenamiento base',cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "\n",
    "def Aplicar_Smote(X_train, X_test, y_train, y_test):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "    X_train_reshaped,X_test_reshaped = normalizacion(X_resampled_smote, X_test)\n",
    "\n",
    "    model = Crear_modelo(X_train_reshaped,y_resampled_smote)\n",
    "    y_pred  = model.predict(X_test_reshaped)\n",
    "\n",
    "    y_pred = (y_pred>0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "    return model,'Smote',cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "\n",
    "def Aplicar_VAE(df_bacteria,bacteria,X_train, X_test, y_train, y_test):\n",
    "    minority_class = df_bacteria[df_bacteria[bacteria] == 1].drop(columns=[bacteria])\n",
    "    scaler = MinMaxScaler()\n",
    "    X_minority_scaled = scaler.fit_transform(minority_class)\n",
    "    # Dimensiones\n",
    "    input_dim = X_minority_scaled.shape[1]\n",
    "    latent_dim = 2  # Espacio latente\n",
    "\n",
    "    # Encoder\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    hidden = Dense(16, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(hidden)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(hidden)\n",
    "\n",
    "    # Sampling\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_hidden = Dense(16, activation='relu')\n",
    "    decoder_output = Dense(input_dim, activation='sigmoid')\n",
    "\n",
    "    hidden_decoded = decoder_hidden(z)\n",
    "    outputs = decoder_output(hidden_decoded)\n",
    "\n",
    "    # Modelo VAE\n",
    "    vae = Model(inputs, outputs)\n",
    "\n",
    "    # Pérdida personalizada\n",
    "    reconstruction_loss = mse(inputs, outputs)\n",
    "    reconstruction_loss *= input_dim\n",
    "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    vae.summary()\n",
    "    vae.fit(X_minority_scaled, X_minority_scaled, epochs=200, batch_size=32, verbose=1)\n",
    "    # Construir el generador (Decoder independiente)\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    hidden_decoded_2 = decoder_hidden(decoder_input)\n",
    "    output_decoded = decoder_output(hidden_decoded_2)\n",
    "    generator = Model(decoder_input, output_decoded)\n",
    "\n",
    "    # Generar datos sintéticos\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    num_samples = pd.Series(y_train).value_counts()[0]-pd.Series(y_train).value_counts()[1]\n",
    "    latent_points = np.random.normal(size=(num_samples, latent_dim))\n",
    "    synthetic_data = generator.predict(latent_points)\n",
    "\n",
    "\n",
    "    # Escalar de vuelta a los valores originales\n",
    "    synthetic_data_original = scaler.inverse_transform(synthetic_data)\n",
    "    X_train_balanced = np.concatenate([X_train, synthetic_data_original])\n",
    "    y_train_balanced = np.concatenate([y_train, np.ones(num_samples)])\n",
    "\n",
    "    X_train_reshaped,X_test_reshaped = normalizacion(X_train_balanced, X_test)\n",
    "    \n",
    "    model = Crear_modelo(X_train_reshaped,y_train_balanced)\n",
    "\n",
    "    y_pred  = model.predict(X_test_reshaped)\n",
    "    y_pred = (y_pred>0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "    return model,'VAE',cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "\n",
    "\n",
    "def Aplicar_DifussionModel(df_bacteria,bacteria,X_train, X_test, y_train, y_test):\n",
    "    # Preprocesamiento\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(X_train)\n",
    "    # Modelo de Difusión\n",
    "    class DiffusionModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(DiffusionModel, self).__init__()\n",
    "            self.model = nn.Sequential( \n",
    "                nn.Linear(input_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.2),  # Regularización Dropout\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.2),  # Regularización Dropout\n",
    "                nn.Linear(32, input_dim)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "    # Función de ruido (Scheduler)\n",
    "    def add_noise(data, timesteps, noise_scale=1.0):\n",
    "        noise = np.random.normal(0, noise_scale, data.shape) * np.sqrt(timesteps / 100)\n",
    "        noisy_data = data + noise\n",
    "        return noisy_data, noise\n",
    "    \n",
    "    # Configuración del modelo\n",
    "    input_dim = scaled_data.shape[1]\n",
    "    model = DiffusionModel(input_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.SmoothL1Loss()  # O Huber Loss\n",
    "\n",
    "    # Scheduler de tasa de aprendizaje\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.9)\n",
    "\n",
    "    # Entrenamiento\n",
    "    scaled_data_tensor = torch.tensor(scaled_data, dtype=torch.float32)\n",
    "    epochs = 1000\n",
    "    losses = []  # Para guardar la pérdida por época\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        timesteps = np.random.randint(1, 100)\n",
    "        noisy_data, noise = add_noise(scaled_data, timesteps)\n",
    "        noisy_data_tensor = torch.tensor(noisy_data, dtype=torch.float32)\n",
    "        noise_tensor = torch.tensor(noise, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_noise = model(noisy_data_tensor)\n",
    "        loss = loss_fn(predicted_noise, noise_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Actualiza la tasa de aprendizaje\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} - Loss: {loss.item()}\")\n",
    "\n",
    "        # Generación de Datos Sintéticos\n",
    "    def generate_synthetic_data(model, num_samples, input_dim):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            synthetic_data = np.random.normal(0, 1, (num_samples, input_dim))\n",
    "            for t in range(100, 0, -1):  # Reverse diffusion\n",
    "                synthetic_data = synthetic_data - model(torch.tensor(synthetic_data, dtype=torch.float32)).numpy() * (t / 100)\n",
    "            return synthetic_data\n",
    "        \n",
    "        \n",
    "    synthetic_data = generate_synthetic_data(model, pd.Series(y_train).value_counts()[0]-pd.Series(y_train).value_counts()[1], input_dim)\n",
    "    synthetic_data_rescaled = scaler.inverse_transform(synthetic_data)\n",
    "\n",
    "        \n",
    "    # Cambiar el tipo de datos a float32\n",
    "    synthetic_samples_numpy = synthetic_data_rescaled.astype(np.float32)\n",
    "\n",
    "    # Mostrar las muestras generadas\n",
    "    synthetic_samples_numpy.shape\n",
    "\n",
    "    X_train_resampled = np.concatenate([X_train,synthetic_samples_numpy])\n",
    "\n",
    "    ones_array = np.ones(pd.Series(y_train).value_counts()[0]-pd.Series(y_train).value_counts()[1])\n",
    "    y_train_resampled = np.concatenate([y_train,ones_array])\n",
    "\n",
    "    #termino de oversampling\n",
    "    X_train_reshaped,X_test_reshaped = normalizacion(X_train_resampled, X_test)\n",
    "    \n",
    "    model = Crear_modelo(X_train_reshaped,y_train_resampled)\n",
    "\n",
    "    y_pred  = model.predict(X_test_reshaped)\n",
    "    y_pred = (y_pred>0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "    return model,'Difussion model',cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "\n",
    "def Aplicar_Copulas(df_bacteria,bacteria,X_train, X_test, y_train, y_test):\n",
    "    minority_class = df_bacteria[df_bacteria[bacteria] == 1].drop(columns=[bacteria])\n",
    "\n",
    "    # Crear un objeto Metadata para el dataset\n",
    "    metadata = SingleTableMetadata()\n",
    "\n",
    "    # Detectar automáticamente los tipos de datos del DataFrame\n",
    "    metadata.detect_from_dataframe(minority_class)\n",
    "    synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "    synthesizer.fit(data=minority_class)\n",
    "\n",
    "    synthetic_data = synthesizer.sample(pd.Series(y_train).value_counts()[0]-pd.Series(y_train).value_counts()[1])\n",
    "    \n",
    "    # Cambiar el tipo de datos a float32\n",
    "    synthetic_samples_numpy_copula = synthetic_data.astype(np.float32)\n",
    "\n",
    "    # Mostrar las muestras generadas\n",
    "    synthetic_samples_numpy_copula.shape\n",
    "    X_train_resampled = np.concatenate([X_train,synthetic_samples_numpy_copula])\n",
    "\n",
    "    ones_array = np.ones(int((pd.Series(y_train).value_counts()[0]-pd.Series(y_train).value_counts()[1])))\n",
    "    y_train_resampled = np.concatenate([y_train,ones_array])\n",
    "\n",
    "\n",
    "    X_train_reshaped,X_test_reshaped = normalizacion(X_train_resampled, X_test)\n",
    "    \n",
    "    model = Crear_modelo(X_train_reshaped,y_train_resampled)\n",
    "\n",
    "    y_pred  = model.predict(X_test_reshaped)\n",
    "    y_pred = (y_pred>0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "    return model,'Copulas',cm,y_pred,X_test_reshaped,X_train_reshaped\n",
    "\n",
    "\n",
    "def columnas_bacterias_fun(df):\n",
    "    vocales = ['a','e','i','o','u']\n",
    "    columnas_bacterias = []\n",
    "    for i in vocales:\n",
    "        for j in df.columns:\n",
    "            if i in j:\n",
    "                columnas_bacterias.append(j)\n",
    "    columnas_bacterias = list(set(columnas_bacterias))\n",
    "    return columnas_bacterias\n",
    "\n",
    "def inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped):\n",
    "    metricas = []\n",
    "\n",
    "    metricas_Dato = ['accuracy','precision','recall','auc','prc']\n",
    "\n",
    "    baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
    "    for name, value in zip(model.metrics_names, baseline_results):\n",
    "        if name in metricas_Dato:\n",
    "            metricas.append(value)\n",
    "    df_resultados.loc[len(df_resultados)] = {\n",
    "        'BD': archivo,\n",
    "        'Nombre antibiotico': bacteria,\n",
    "        'Metodo de Oversampling':tipo_entrenamiento,\n",
    "        'Accuracy':metricas[0],\n",
    "        'Precision':metricas[1],\n",
    "        'Recall':metricas[2],\n",
    "        'AUC':metricas[3],\n",
    "        'PRC':metricas[4]\n",
    "    }\n",
    "\n",
    "\n",
    "files_list = os.listdir('SetDatos/')\n",
    "for archivo in ['e_coli_driams_b_2000_20000Da_v2 (1).csv']:#files_list\n",
    "    df = pd.read_csv('SetDatos/'+archivo)\n",
    "    df = df.drop(columns=['code','species'])\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    columnas_bacterias = columnas_bacterias_fun(df)\n",
    "    df_resultados = pd.DataFrame({\n",
    "    'BD': [],\n",
    "    'Nombre antibiotico': [],\n",
    "    'Metodo de Oversampling': [],\n",
    "    'Accuracy':[],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'AUC':[],\n",
    "    'PRC':[]\n",
    "    })\n",
    "    for bacteria in columnas_bacterias: #columnas_bacterias\n",
    "\n",
    "        try:\n",
    "            print('Archivo:',archivo,'Bacteria:',bacteria)\n",
    "            columnas_bacterias_sin_bacteria = [b for b in columnas_bacterias if b != bacteria]\n",
    "            df_bacteria = df.drop(columns = columnas_bacterias_sin_bacteria)\n",
    "            bacteria = df_bacteria.columns[-1]\n",
    "            X = df_bacteria.iloc[:, 0:-1].values  # variables independientes (espectros de masa)\n",
    "            y = df_bacteria.iloc[:, -1].values    # variable dependientes (resistencia a ciprofloxacin)\n",
    "            X = np.asarray(X).astype(np.float32)\n",
    "            y = np.asarray(y).astype(np.float32)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)\n",
    " \n",
    "            #resultado sin oversampling\n",
    "            model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped = entrenamiento_base(X_train, X_test, y_train, y_test)\n",
    "            inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped)\n",
    "        \n",
    "            # Liberar memoria\n",
    "            del model, tipo_entrenamiento, y_pred, cm, X_test_reshaped, X_train_reshaped\n",
    "            gc.collect()  # Forzar recolección de basura\n",
    "   \n",
    "            #resultado con smote\n",
    "            model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped = Aplicar_Smote(X_train, X_test, y_train, y_test)\n",
    "            inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped)\n",
    "\n",
    "            # Liberar memoria\n",
    "            del model, tipo_entrenamiento, y_pred, cm, X_test_reshaped, X_train_reshaped\n",
    "            gc.collect()  # Forzar recolección de basura\n",
    "\n",
    "            #resultado con VAE\n",
    "            model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped = Aplicar_VAE(df_bacteria,bacteria,X_train, X_test, y_train, y_test)\n",
    "            inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped)\n",
    "            \n",
    "            # Liberar memoria\n",
    "            del model, tipo_entrenamiento, y_pred, cm, X_test_reshaped, X_train_reshaped\n",
    "            gc.collect()  # Forzar recolección de basura\n",
    "\n",
    "            \n",
    "            #resultado con Difussion model\n",
    "            model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped = Aplicar_DifussionModel(df_bacteria,bacteria,X_train, X_test, y_train, y_test)\n",
    "            inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped)\n",
    "            \n",
    "            # Liberar memoria\n",
    "            del model, tipo_entrenamiento, y_pred, cm, X_test_reshaped, X_train_reshaped\n",
    "            gc.collect()  # Forzar recolección de basura\n",
    "\n",
    "            #resultado con Difussion model\n",
    "            model,tipo_entrenamiento,cm,y_pred,X_test_reshaped,X_train_reshaped = Aplicar_Copulas(df_bacteria,bacteria,X_train, X_test, y_train, y_test)\n",
    "            inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped)\n",
    "            \n",
    "            # Liberar memoria\n",
    "            del model, tipo_entrenamiento, y_pred, cm, X_test_reshaped, X_train_reshaped\n",
    "            gc.collect()  # Forzar recolección de basura\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            with open('resultados/resultados.txt', 'a') as archivo_:\n",
    "                print(\"Error:\",e,file = archivo_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del columnas_bacterias_sin_bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n        print(\\'-----------------------------------------------------\\n\\n\\',\\'nombre de archivo:\\', archivo, \\'\\nBacteria:\\', bacteria, \"\\n\\nTipo de entrenamiento:\",tipo_entrenamiento,\\'\\n\\nconfusion_matrix:\\n\\', cm, file=archivo_)\\n        target_names=[\"0\",\"1\"]\\n        print(\\'\\n\\n\\',classification_report(y_test, y_pred, target_names=target_names), file=archivo_)\\n\\n        train_predictions_baseline = model.predict(X_train_reshaped, batch_size=10)\\n        test_predictions_baseline = model.predict(X_test_reshaped, batch_size=10)\\n        print(\\'\\n\\n\\')\\n        baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\\n        for name, value in zip(model.metrics_names, baseline_results):\\n            print(name, \\': \\', value, file=archivo_)   '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inscripcion_resultados(model,archivo,bacteria,cm,y_test, y_pred,tipo_entrenamiento,X_test_reshaped,X_train_reshaped):\n",
    "    with open('resultados/resultados.txt', 'a') as archivo_:\n",
    "        # Redirige la salida estándar al archivo\n",
    "        print('-----------------------------------------------------\\n\\n','nombre de archivo:', archivo, '\\nBacteria:', bacteria, \"\\n\\nTipo de entrenamiento:\",tipo_entrenamiento,'\\n\\nconfusion_matrix:\\n', cm, file=archivo_)\n",
    "\n",
    "        print('-----------------------------------------------------\\n\\n','nombre de archivo:', archivo, '\\nBacteria:', bacteria, \"\\n\\nTipo de entrenamiento:\",tipo_entrenamiento,'\\n\\nconfusion_matrix:\\n', cm, file=archivo_)\n",
    "        target_names=[\"0\",\"1\"]\n",
    "        print('\\n\\n',classification_report(y_test, y_pred, target_names=target_names), file=archivo_)\n",
    "\n",
    "        train_predictions_baseline = model.predict(X_train_reshaped, batch_size=10)\n",
    "        test_predictions_baseline = model.predict(X_test_reshaped, batch_size=10)\n",
    "        print('\\n\\n')\n",
    "        baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
    "        for name, value in zip(model.metrics_names, baseline_results):\n",
    "            print(name, ': ', value, file=archivo_)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "\n",
      " nombre de archivo: e_coli_driams_b_2000_20000Da_v2 (1).csv \n",
      "Bacteria: Cefepime \n",
      "\n",
      "Tipo de entrenamiento: Entrenamiento base \n",
      "\n",
      "confusion_matrix:\n",
      " [[29  5]\n",
      " [ 7  2]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metricas = []\n",
    "\n",
    "metricas_Dato = ['accuracy','precision','recall','auc','prc']\n",
    "\n",
    "baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    if name in metricas_Dato:\n",
    "        metricas.append(value)\n",
    "df_resultados.loc[len(df_resultados)] = {\n",
    "    'BD': archivo,\n",
    "    'Nombre antibiotico': bacteria,\n",
    "    'Metodo de Oversampling':tipo_entrenamiento,\n",
    "    'Accuracy':metricas[0],\n",
    "    'Precision':metricas[1],\n",
    "    'Recall':metricas[2],\n",
    "    'AUC':metricas[3],\n",
    "    'PRC':metricas[4]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame({\n",
    "    'Nombre antibiotico': [],\n",
    "    'Metodo de Oversampling': [],\n",
    "    'Metricas': [],\n",
    "    'BD': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'AUC':[],\n",
    "    'PRC':[]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BD</th>\n",
       "      <th>Nombre antibiotico</th>\n",
       "      <th>Metodo de Oversampling</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>PRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Piperacillin-Tazobactam</td>\n",
       "      <td>Entrenamiento Smote</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.656060</td>\n",
       "      <td>0.447203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento Smote</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.650327</td>\n",
       "      <td>0.366911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Ceftriaxone</td>\n",
       "      <td>Entrenamiento Smote</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.389407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Ciprofloxacin</td>\n",
       "      <td>Entrenamiento Smote</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.760753</td>\n",
       "      <td>0.575319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        BD       Nombre antibiotico  \\\n",
       "0  e_coli_driams_b_2000_20000Da_v2 (1).csv  Piperacillin-Tazobactam   \n",
       "1  e_coli_driams_b_2000_20000Da_v2 (1).csv                 Cefepime   \n",
       "2  e_coli_driams_b_2000_20000Da_v2 (1).csv              Ceftriaxone   \n",
       "3  e_coli_driams_b_2000_20000Da_v2 (1).csv            Ciprofloxacin   \n",
       "\n",
       "  Metodo de Oversampling  Accuracy  Precision    Recall       AUC       PRC  \n",
       "0    Entrenamiento Smote  0.697674   0.363636  0.400000  0.656060  0.447203  \n",
       "1    Entrenamiento Smote  0.697674   0.250000  0.222222  0.650327  0.366911  \n",
       "2    Entrenamiento Smote  0.744186   0.428571  0.666667  0.750000  0.389407  \n",
       "3    Entrenamiento Smote  0.604651   0.391304  0.750000  0.760753  0.575319  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_fila = {\n",
    "    'Nombre antibiotico': 'Amoxicilina',\n",
    "    'Metodo de Oversampling': 'SMOTE',\n",
    "    'Metricas': {'accuracy': 0.89, 'recall': 0.85},\n",
    "    'BD': 'Base1'\n",
    "}\n",
    "\n",
    "df_resultados = pd.concat([df_resultados, pd.DataFrame([nueva_fila])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre antibiotico</th>\n",
       "      <th>Metodo de Oversampling</th>\n",
       "      <th>Metricas</th>\n",
       "      <th>BD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amoxicilina</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>{'accuracy': 0.89, 'recall': 0.85}</td>\n",
       "      <td>Base1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nombre antibiotico Metodo de Oversampling  \\\n",
       "0        Amoxicilina                  SMOTE   \n",
       "\n",
       "                             Metricas     BD  \n",
       "0  {'accuracy': 0.89, 'recall': 0.85}  Base1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.loc[len(df_resultados)] = {\n",
    "    'Nombre antibiotico': 'Ciprofloxacino',\n",
    "    'Metricas': {'accuracy': 0.75}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre antibiotico</th>\n",
       "      <th>Metodo de Oversampling</th>\n",
       "      <th>Metricas</th>\n",
       "      <th>BD</th>\n",
       "      <th>Antibiotico</th>\n",
       "      <th>Tipo de entrenamiento</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento base</td>\n",
       "      <td>0.72093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e_coli_driams_b_2000_20000Da_v2 (1).csv</td>\n",
       "      <td>Cefepime</td>\n",
       "      <td>Entrenamiento base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ciprofloxacino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'accuracy': 0.75}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ciprofloxacino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'accuracy': 0.75}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ciprofloxacino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'accuracy': 0.75}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nombre antibiotico  Metodo de Oversampling            Metricas  \\\n",
       "0                NaN                     NaN                 NaN   \n",
       "1                NaN                     NaN                 NaN   \n",
       "2                NaN                     NaN                 NaN   \n",
       "3                NaN                     NaN                 NaN   \n",
       "4                NaN                     NaN                 NaN   \n",
       "5     Ciprofloxacino                     NaN  {'accuracy': 0.75}   \n",
       "6     Ciprofloxacino                     NaN  {'accuracy': 0.75}   \n",
       "7     Ciprofloxacino                     NaN  {'accuracy': 0.75}   \n",
       "\n",
       "                                        BD Antibiotico Tipo de entrenamiento  \\\n",
       "0  e_coli_driams_b_2000_20000Da_v2 (1).csv    Cefepime    Entrenamiento base   \n",
       "1  e_coli_driams_b_2000_20000Da_v2 (1).csv    Cefepime    Entrenamiento base   \n",
       "2  e_coli_driams_b_2000_20000Da_v2 (1).csv    Cefepime    Entrenamiento base   \n",
       "3  e_coli_driams_b_2000_20000Da_v2 (1).csv    Cefepime    Entrenamiento base   \n",
       "4  e_coli_driams_b_2000_20000Da_v2 (1).csv    Cefepime    Entrenamiento base   \n",
       "5                                      NaN         NaN                   NaN   \n",
       "6                                      NaN         NaN                   NaN   \n",
       "7                                      NaN         NaN                   NaN   \n",
       "\n",
       "   accuracy  precision    recall       auc       prc  \n",
       "0   0.72093        NaN       NaN       NaN       NaN  \n",
       "1       NaN   0.285714       NaN       NaN       NaN  \n",
       "2       NaN        NaN  0.222222       NaN       NaN  \n",
       "3       NaN        NaN       NaN  0.633987       NaN  \n",
       "4       NaN        NaN       NaN       NaN  0.254741  \n",
       "5       NaN        NaN       NaN       NaN       NaN  \n",
       "6       NaN        NaN       NaN       NaN       NaN  \n",
       "7       NaN        NaN       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
